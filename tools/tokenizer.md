**Tokenizer**: Berechnet die Anzahl Tokens, Wörter und Sätze in einem Text oder einer Liste von Texten. Die Tokenisierung erfolgt mit dem Modell *gpt-3.5-turbo*.


